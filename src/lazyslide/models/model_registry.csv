name,keys,is_gated,model_type,module,github_url,hf_url,paper_url,description
CONCH,conch,1,multimodal,CONCH,https://github.com/mahmoodlab/CONCH,https://huggingface.co/MahmoodLab/conch,https://doi.org/10.1038/s41591-024-02856-4,Multimodal foundation model
PLIP,plip,0,multimodal,PLIP,https://github.com/PathologyFoundation/plip,https://huggingface.co/vinid/plip,https://doi.org/10.1038/s41591-023-02504-3,Multimodal foundation model
Prism,prism,1,multimodal,Prism,,https://huggingface.co/paige-ai/Prism,https://doi.org/10.48550/arXiv.2405.10254,Slide-Level multimodal generative model
Titan,"titan, conch_v1.5",1,multimodal,Titan,https://github.com/mahmoodlab/TITAN,https://huggingface.co/MahmoodLab/TITAN,https://doi.org/10.48550/arXiv.2411.19666,Multimodal foundation model
Uni,uni,1,vision,UNI,https://github.com/mahmoodlab/UNI,https://huggingface.co/MahmoodLab/UNI,https://doi.org/10.1038/s41591-024-02857-3,Vision foundation model
Uni2,uni2,1,vision,UNI2,https://github.com/mahmoodlab/UNI,https://huggingface.co/MahmoodLab/UNI2-h,https://doi.org/10.1038/s41591-024-02857-3,Vision foundation model
GigaPath,gigapath,1,vision,GigaPath,https://github.com/prov-gigapath/prov-gigapath,https://huggingface.co/prov-gigapath/prov-gigapath,https://doi.org/10.1038/s41586-024-07441-w,Vision foundation model
Virchow,virchow,1,vision,Virchow,,https://huggingface.co/paige-ai/Virchow,https://doi.org/10.1038/s41591-024-03141-0,Vision foundation model
Virchow2,virchow2,1,vision,Virchow2,,https://huggingface.co/paige-ai/Virchow2,https://doi.org/10.48550/arXiv.2408.00738,Vision foundation model
Phikon,phikon,0,vision,Phikon,https://github.com/owkin/HistoSSLscaling/,https://huggingface.co/owkin/phikon,https://doi.org/10.1101/2023.07.21.23292757,Vision foundation model
PhikonV2,phikonv2,0,vision,PhikonV2,https://github.com/owkin,https://huggingface.co/owkin/phikon-v2,https://doi.org/10.48550/arXiv.2409.09173,Vision foundation model
H-optimus-0,h-optimus-0,0,vision,HOptimus0,https://github.com/bioptimus,https://huggingface.co/bioptimus/H-optimus-0,,Vision foundation model
H-optimus-1,h-optimus-1,1,vision,HOptimus1,https://github.com/bioptimus,https://huggingface.co/bioptimus/H-optimus-1,,Vision foundation model
H0-mini,h0-mini,1,vision,H0Mini,https://github.com/bioptimus,https://huggingface.co/bioptimus/H0-mini,https://doi.org/10.48550/arXiv.2501.16239,Vision foundation model
CONCHVision,conch_vision,1,vision,CONCHVision,https://github.com/mahmoodlab/CONCH,https://huggingface.co/MahmoodLab/conch,https://doi.org/10.1038/s41591-024-02856-4,Multimodal foundation model
PLIPVision,plip_vision,0,vision,PLIPVision,https://github.com/PathologyFoundation/plip,https://huggingface.co/vinid/plip,https://doi.org/10.1038/s41591-023-02504-3,Multimodal foundation model
NuLite,nulite,0,segmentation,NuLite,https://github.com/CosmoIknosLab/NuLite,,https://doi.org/10.48550/arXiv.2408.01797,Cell segmentation and classification
InstanSeg,instanseg,0,segmentation,Instanseg,https://github.com/instanseg/instanseg,,https://doi.org/10.48550/arXiv.2408.15954,Cell segmentation
GrandQC-Tissue,grandqc-tissue,0,segmentation,GrandQCTissue,https://github.com/cpath-ukk/grandqc,,https://doi.org/10.1038/s41467-024-54769-y,Tissue segmentation
GrandQC-Artifact,grandqc-artifact,0,segmentation,GrandQCArtifact,https://github.com/cpath-ukk/grandqc,,https://doi.org/10.1038/s41467-024-54769-y,Artifact segmentation
Midnight,midnight,0,vision,Midnight,https://github.com/kaiko-ai/midnight,https://huggingface.co/kaiko-ai/midnight,https://doi.org/10.48550/arXiv.2504.05186,Vision foundation model
HibouB,hibou-b,1,vision,HibouB,https://github.com/HistAI/hibou/tree/main,https://huggingface.co/histai/hibou-b,https://doi.org/10.48550/arXiv.2406.05074,Foundation Vision Transformer
HibouL,hibou-l,1,vision,HibouL,https://github.com/HistAI/hibou/tree/main,https://huggingface.co/histai/hibou-l,https://doi.org/10.48550/arXiv.2406.05074,Foundation Vision Transformer
OmiCLIP,omiclip,1,multimodal,OmiCLIP,https://github.com/GuangyuWangLab2021/Loki,https://huggingface.co/WangGuangyuLab/Loki,https://doi.org/10.1038/s41592-025-02707-1,Multimodal foundation model
CTransPath,ctranspath,0,vision,CTransPath,https://github.com/Xiyue-Wang/TransPath,,https://doi.org/10.1016/j.media.2022.102559,Vision foundation model
CHIEF,chief,0,vision,CHIEF,https://github.com/hms-dbmi/CHIEF,,https://doi.org/10.1038/s41586-024-07894-z,Vision foundation model
FocusLiteNN,focuslitenn,0,tile_prediction,FocusLiteNN,https://github.com/icbcbicc/FocusLiteNN,,https://doi.org/10.48550/arXiv.2007.06565,Prediction of image focus level
PathProfilerQC,pathprofilerqc,0,tile_prediction,PathProfilerQC,https://github.com/MaryamHaghighat/PathProfiler,,https://doi.org/10.1038/s41598-022-08351-5,Prediction of image quality
PathProfilerTissueSegmentation,pathprofiler,0,segmentation,PathProfilerTissueSegmentation,https://github.com/MaryamHaghighat/PathProfiler,,https://doi.org/10.1038/s41598-022-08351-5,Tissue segmentation
Spider,spider,1,tile_prediction,Spider,,https://huggingface.co/collections/histai/spider-models-and-datasets-6814834eca365b006389c117,,Tile prediction model on different organs
SpiderBreast,spider-breast,1,tile_prediction,SpiderBreast,,https://huggingface.co/collections/histai/spider-models-and-datasets-6814834eca365b006389c117,,Tile prediction model on different organs
SpiderColorectal,spider-colorectal,1,tile_prediction,SpiderColorectal,,https://huggingface.co/collections/histai/spider-models-and-datasets-6814834eca365b006389c117,,Tile prediction model on different organs
SpiderSkin,spider-skin,1,tile_prediction,SpiderSkin,,https://huggingface.co/collections/histai/spider-models-and-datasets-6814834eca365b006389c117,,Tile prediction model on different organs
SpiderThorax,spider-thorax,1,tile_prediction,SpiderThorax,,https://huggingface.co/collections/histai/spider-models-and-datasets-6814834eca365b006389c117,,Tile prediction model on different organs
Cellpose,cellpose,0,segmentation,Cellpose,https://github.com/MouseLand/cellpose,https://huggingface.co/mouseland/cellpose-sam,https://doi.org/10.1038/s41592-020-01018-x,Cell segmentation model